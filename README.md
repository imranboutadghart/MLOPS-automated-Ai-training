# Distributed Continuous Training Pipeline

A production-style MLOps pipeline that automates model training, evaluation, and deployment using modern distributed computing and orchestration technologies.

## ğŸš€ Features

- **Automated Scheduling**: Configurable training schedules (hourly, daily, weekly)
- **Distributed Training**: Multi-GPU training with HuggingFace Accelerate
- **Model Registry**: MLflow integration for versioning and artifact management
- **Canary Deployments**: Gradual traffic shifting with automatic rollback
- **Shadow Deployments**: A/B testing without production impact
- **Full Observability**: Metrics, logging, and health monitoring

## ğŸ“‹ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Orchestration Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Airflow   â”‚â”€â”€â–¶â”‚   Scheduler   â”‚â”€â”€â–¶â”‚ Daily/Weekly/Hourly  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Data Pipeline                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Ingestion  â”‚â”€â”€â–¶â”‚ Preprocessing â”‚â”€â”€â–¶â”‚ Feature Store        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Training Layer                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ HF Accelerate   â”‚â”€â”€â–¶â”‚ PyTorch DDP  â”‚â”€â”€â–¶â”‚ Multi-GPU       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Registry & Deployment                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  MLflow    â”‚â”€â”€â–¶â”‚  Promotion   â”‚â”€â”€â–¶â”‚ Canary/Shadow Deploy â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| Orchestration | Apache Airflow 2.8+ |
| Deep Learning | PyTorch 2.1+ |
| Distributed Training | HuggingFace Accelerate |
| Data Processing | Pandas, NumPy |
| Model Registry | MLflow 2.10+ |
| Object Storage | MinIO |
| Containerization | Docker, Docker Compose |

## ğŸ“ Project Structure

```
distributed-training-pipeline/
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/                    # Airflow DAGs
â”‚   â”‚   â”œâ”€â”€ continuous_training_dag.py
â”‚   â”‚   â”œâ”€â”€ data_pipeline_dag.py
â”‚   â”‚   â””â”€â”€ deployment_dag.py
â”‚   â”œâ”€â”€ plugins/                 # Custom operators
â”‚   â””â”€â”€ config/                  # Airflow config
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                    # Data ingestion & preprocessing
â”‚   â”œâ”€â”€ training/                # Models, trainer, distributed training
â”‚   â”œâ”€â”€ registry/                # MLflow client & model promotion
â”‚   â”œâ”€â”€ deployment/              # Canary & shadow deployment
â”‚   â””â”€â”€ utils/                   # Config, logging, monitoring
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ training_config.yaml     # Training hyperparameters
â”‚   â”œâ”€â”€ accelerate_config.yaml   # DDP configuration
â”‚   â””â”€â”€ deployment_config.yaml   # Deployment settings
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.airflow       # Airflow image with ML deps
â”‚   â”œâ”€â”€ Dockerfile.training      # GPU training image
â”‚   â””â”€â”€ docker-compose.yml       # Full stack
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_environment.sh     # Environment setup
â”‚   â””â”€â”€ start_training.sh        # Launch training
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_pipeline.py         # Integration tests
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites

- Docker and Docker Compose
- NVIDIA GPU with CUDA support (optional, for GPU training)
- Python 3.10+

### 1. Clone and Setup

```bash
# Clone repository
git clone <repository-url>
cd distributed-training-pipeline

# Setup environment
chmod +x scripts/*.sh
./scripts/setup_environment.sh
```

### 2. Start the Stack

```bash
# Start all services
cd docker
docker-compose up -d

# Check status
docker-compose ps
```

### 3. Access Services

| Service | URL | Credentials |
|---------|-----|-------------|
| Airflow UI | http://localhost:8080 | admin / admin |
| MLflow UI | http://localhost:5000 | - |
| MinIO Console | http://localhost:9001 | minioadmin / minioadmin |

### 4. Trigger Training

```bash
# Via Airflow UI
# Go to http://localhost:8080 and trigger 'continuous_training_dag'
 
# Or via CLI
docker-compose exec airflow-scheduler airflow dags trigger continuous_training_dag
```

## ğŸ“Š Training Configuration

Edit `configs/training_config.yaml`:

```yaml
model:
  name: "classifier"
  hidden_sizes: [512, 256, 128]
  dropout: 0.3

training:
  epochs: 10
  batch_size: 64
  learning_rate: 0.001
  mixed_precision: "fp16"

scheduler:
  type: "cosine"
  warmup_steps: 100
```

## ğŸ”„ Deployment Strategies

### Canary Deployment

Gradual traffic shifting: 1% â†’ 5% â†’ 25% â†’ 50% â†’ 100%

```yaml
canary:
  initial_weight: 0.01
  weight_steps: [0.05, 0.25, 0.50, 1.0]
  step_duration_seconds: 300
  rollback_on_failure: true
```

### Shadow Deployment

Parallel inference for A/B testing without production impact.

## ğŸ§ª Running Tests

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ -v --cov=src --cov-report=html
```

## ğŸ“ˆ Model Promotion Flow

1. **Training** â†’ Model trained and evaluated
2. **Staging** â†’ Model passes threshold checks (accuracy â‰¥ 0.85, F1 â‰¥ 0.80)
3. **Production** â†’ Model outperforms current champion by â‰¥ 1%

## ğŸ”§ Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `MLFLOW_TRACKING_URI` | MLflow server URL | http://localhost:5000 |
| `AWS_ACCESS_KEY_ID` | MinIO access key | minioadmin |
| `AWS_SECRET_ACCESS_KEY` | MinIO secret key | minioadmin |

## ğŸ“š Documentation

- [Training Guide](docs/training.md)
- [Deployment Guide](docs/deployment.md)
- [API Reference](docs/api.md)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests
5. Submit a pull request

## ğŸ“„ License

